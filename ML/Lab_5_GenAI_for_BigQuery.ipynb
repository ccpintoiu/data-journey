{
  "cells": [
    {
      "cell_type": "code",
      "id": "vO34btTXeURhyLNBtM45kn2T",
      "metadata": {
        "tags": [],
        "id": "vO34btTXeURhyLNBtM45kn2T"
      },
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 5:** GenAI for BigQuery\n",
        "This lab will showcase some Generative AI features that can be utilized comfortably within BigQuery. While going through this lab you will learn:\n",
        "* **Creating a model**: To be able to use GenAI we will create a model using BigQueryML syntax which will be remotely connected to our VertexAI platform.\n",
        "* **Generation**: After successful model creation we will engineer a suitable prompt based on our data and use this to generate new text utilizing fitting BigQuery ML syntax as well.\n",
        "\n",
        "What we'd like to achieve contentwise is, that we generate a message for each user, depending on churn or not, and let them know about their current gaming status."
      ],
      "metadata": {
        "id": "-SxlSehxUszr"
      },
      "id": "-SxlSehxUszr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1:** Parameters and Authentication\n",
        "Authenticate yourself against Google Cloud Platform."
      ],
      "metadata": {
        "id": "o0kHEAF3f5uX"
      },
      "id": "o0kHEAF3f5uX"
    },
    {
      "cell_type": "code",
      "source": [
        "project_id   = \"<project-id>\"\n",
        "team_name    = \"<team-name>\"\n",
        "location     = \"us\" #This is currently necessary\n",
        "region       = \"us-central1\"\n",
        "\n",
        "dataset_name = \"datathon_ds_{}\".format(team_name)\n",
        "bucket_name  = \"gs://{}_{}\".format(project_id,dataset_name)"
      ],
      "metadata": {
        "id": "OXnI4KeFWLEq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718987512355,
          "user_tz": 240,
          "elapsed": 274,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "OXnI4KeFWLEq",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import google.auth\n",
        "\n",
        "credentials, project_id = google.auth.default()\n",
        "client = bigquery.Client(credentials=credentials, project=project_id)\n"
      ],
      "metadata": {
        "id": "YnWHuVRovafU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1718987528783,
          "user_tz": 240,
          "elapsed": 14068,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "YnWHuVRovafU",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2:** Create full dataset\n",
        "As a first step to incorporate GenAI features into BigQuery, we need the necessary data to work on.\n",
        "For this we'll create another view of our raw data which incorporates the full dataset, as in Lab 1."
      ],
      "metadata": {
        "id": "kIX-rXIAa5Z2"
      },
      "id": "kIX-rXIAa5Z2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create view for the full dataset\n",
        "view_id  = \"{}.{}.cc_full_dataset_for_genai\".format(project_id, dataset_name)\n",
        "view     = bigquery.Table(view_id)\n",
        "\n",
        "view.view_query = f'''\n",
        "\n",
        "  SELECT\n",
        "    dem.*,\n",
        "    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\n",
        "    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\n",
        "    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\n",
        "    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\n",
        "    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\n",
        "    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\n",
        "    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\n",
        "    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\n",
        "    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\n",
        "    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\n",
        "    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\n",
        "    ret.user_first_engagement,\n",
        "    ret.churned\n",
        "  FROM\n",
        "    {dataset_name}.user_returninginfo ret\n",
        "  LEFT OUTER JOIN\n",
        "    {dataset_name}.user_demographics dem\n",
        "  ON\n",
        "    ret.user_pseudo_id = dem.user_pseudo_id\n",
        "  LEFT OUTER JOIN\n",
        "    {dataset_name}.user_aggregate_behavior beh\n",
        "  ON\n",
        "    ret.user_pseudo_id = beh.user_pseudo_id\n",
        "  WHERE ret.bounced = 0\n",
        "'''\n",
        "\n",
        "# Create the view\n",
        "view = client.create_table(view, exists_ok=True)\n",
        "print(f\"Created {view.table_type}: {str(view.reference)}\")"
      ],
      "metadata": {
        "id": "y4pwZC5aa4ci"
      },
      "id": "y4pwZC5aa4ci",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since further table alterations can not be done on views, we are going to create a new BigQuery Table according to the previously created view.\n",
        "\n",
        "Please replace the placeholder for project ID and dataset name in full text within the following code."
      ],
      "metadata": {
        "id": "OVomrO-nKxm8"
      },
      "id": "OVomrO-nKxm8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace placeholders with your actual project ID and Dataset ID with your actual view name and desired new table name\n",
        "view_id = '<project-id>.<dataset-name>.cc_full_dataset_for_genai'\n",
        "table_id = '<project-id>.<dataset-name>.cc_full_dataset_table'\n",
        "\n",
        "# Extract the SQL query from the view\n",
        "query_job = client.query(f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `{view_id}`\n",
        "\"\"\")\n",
        "\n",
        "# Create the table from the view query\n",
        "table = bigquery.Table(table_id)\n",
        "job_config = bigquery.QueryJobConfig(destination=table_id)\n",
        "\n",
        "job = client.query(query_job.query, job_config=job_config)\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()\n",
        "\n",
        "print(f\"Table {table_id} created successfully from view!\")"
      ],
      "metadata": {
        "id": "Jlw3-VaWE3K6"
      },
      "id": "Jlw3-VaWE3K6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3**: The prompt\n",
        "\n",
        "Now, to utilize GenAI features, we need a prompt.\n",
        "\n",
        "For this there are two ways to go.\n",
        "\n",
        "One possibility is that one can specify an additional \"prompt\" column in our dataset and insert the prompts there. The other method would not create an additional column and have another prompt variable to specifiy in the query.\n",
        "Depending on your use case you could play around with both, but here we will use the method with an additional prompt column."
      ],
      "metadata": {
        "id": "W2F8qzJZrqMg"
      },
      "id": "W2F8qzJZrqMg"
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new column called 'prompt'\n",
        "# replace project ID and dataset ID with your specific values in full text\n",
        "%%bigquery --project $project_id\n",
        "ALTER TABLE `<project-id>.<dataset-name>.cc_full_dataset_table`\n",
        "ADD COLUMN prompt string;"
      ],
      "metadata": {
        "id": "2cvXvyQHvfWV"
      },
      "id": "2cvXvyQHvfWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we successfully created the new prompt column we now specify how the prompt ist going to look like.\n",
        "\n",
        "By default the same prompt would be inserted into each cell. If we are interested in creating a specific promt base on other column values we'd have to go into more advanced prompting, like in the following example."
      ],
      "metadata": {
        "id": "kZmJdmHpOkd-"
      },
      "id": "kZmJdmHpOkd-"
    },
    {
      "cell_type": "code",
      "source": [
        "# replace project ID and dataset ID with your specific values in full text\n",
        "%%bigquery --project $project_id\n",
        "\n",
        "UPDATE `<project-id>.<dataset-name>.cc_full_dataset_table`\n",
        "SET prompt = CASE\n",
        "    WHEN churned = 1 THEN CONCAT(\"Please generate an uplifting message to tell the that they haven't quit the game and it seems that they are enjoying it. Please also include a reference to the number of user engagements which will follow after this prompt. (3 sentences max)\", CAST (cnt_user_engagement AS STRING))\n",
        "    ELSE CONCAT(\"Please generate a sad message to tell the user that it seems like they have quit the game. Then try encouraging them to rejoin the game again while including a reference to the number of user engagements which will follow after this prompt. (3 sentences max)\", CAST (cnt_user_engagement AS STRING))\n",
        "END\n",
        "WHERE TRUE;"
      ],
      "metadata": {
        "id": "itkpSruSQKPP"
      },
      "id": "itkpSruSQKPP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(Optional)**\n",
        "You could try and incorporate the respective user's language in the prompt as well in a further try. Just concatenate a further column's value in the prompt and refer to it as well.\n",
        "\n",
        "The user's country of origin is listed in the column 'country'."
      ],
      "metadata": {
        "id": "sdZARQmQxjco"
      },
      "id": "sdZARQmQxjco"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4** Create a model\n",
        "\n",
        "After having our prompt column in place we need to create a model within BigQuery to be able to utilize GenAI capabilities.\n",
        "\n",
        "Firstly, we need to create an external connection within BigQuery to connect remotely to Vertex AI models."
      ],
      "metadata": {
        "id": "C5p94gu2NidX"
      },
      "id": "C5p94gu2NidX"
    },
    {
      "cell_type": "code",
      "source": [
        "#change project ID and connection name (choose a name for your connection)\n",
        "!bq mk --connection --location='us' --project_id='<project-id>' \\\n",
        "    --connection_type=CLOUD_RESOURCE <connection-name>"
      ],
      "metadata": {
        "id": "PGQxK208V8T0"
      },
      "id": "PGQxK208V8T0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now utilize this new connection to create a model.\n",
        "\n",
        "The model **Text Bison** was chosen for this notebook, but feel free to play with other LLMs as well via their endpoints."
      ],
      "metadata": {
        "id": "PC-_he4DdbxU"
      },
      "id": "PC-_he4DdbxU"
    },
    {
      "cell_type": "code",
      "source": [
        "# replace project ID and connection ID with your specific values in full text\n",
        "%%bigquery --project $project_id\n",
        "\n",
        "CREATE MODEL `<project-id>.<dataset-name>.<model-name>` #set your model's name\n",
        "REMOTE WITH CONNECTION `<project-id>.us.<connection-name>`\n",
        "OPTIONS (\n",
        "\n",
        "  ENDPOINT = 'https://us-central1-aiplatform.googleapis.com/v1/projects/datajourney030524/locations/us-central1/publishers/google/models/text-bison:predict'\n",
        ");"
      ],
      "metadata": {
        "id": "pG5sZ6GTvrSZ"
      },
      "id": "pG5sZ6GTvrSZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **!!Important!!**\n",
        "Before hopping into generation, we have to grant the generated service account from the new connection the necessary IAM permissions.\n",
        "\n",
        "Go to the BigQuery page in the console and click on the just created connection. The page will show you a service account associated with it.\n",
        "\n",
        "Insert this service account as the principal on the IAM page when clicking on 'Grant access'.\n",
        "\n",
        "Grant this new principal access to the following:\n",
        "\n",
        "* Vertex AI User\n",
        "* BigQuery Connection User\n",
        "* BigQuery Data Editor"
      ],
      "metadata": {
        "id": "NPXEP-OLnXc4"
      },
      "id": "NPXEP-OLnXc4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5** Generate message\n",
        "\n",
        "Now it's time to start generating messages for every user based on their specific gaming behavior!\n",
        "\n",
        "Since the original table has several ten thousand entries it will take quite a while to finish generating.\n",
        "\n",
        "Therefore for demonstration purposes we'll create a quick table which only includes the first 100 entries from our original table."
      ],
      "metadata": {
        "id": "PlG5LHq5enrQ"
      },
      "id": "PlG5LHq5enrQ"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project $project_id\n",
        "\n",
        "CREATE TABLE `<project-id>.<dataset-name>.cc_full_dataset_table_100` AS\n",
        "SELECT *\n",
        "FROM `<project-id>.<dataset-name>.cc_full_dataset_table`\n",
        "LIMIT 100;\n"
      ],
      "metadata": {
        "id": "Uc1QlR14qg2K"
      },
      "id": "Uc1QlR14qg2K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now the fun part! Let's start generating the messages. To see them in full, it's also useful to navigate to your BigQuery in the Cloud Console and query the following there as well."
      ],
      "metadata": {
        "id": "1ZKA2wLhr6nh"
      },
      "id": "1ZKA2wLhr6nh"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project $project_id\n",
        "\n",
        "SELECT * FROM\n",
        "\n",
        "ML.GENERATE_TEXT(\n",
        "  MODEL `<project-id>.<dataset-name>.model1_test`,\n",
        "  TABLE `<project-id>.<dataset-name>.cc_full_dataset_table_100`,\n",
        "  STRUCT (\n",
        "    0.2 AS temperature,\n",
        "    75 AS max_output_tokens,\n",
        "    0.3 AS top_p,\n",
        "    TRUE AS flatten_json_output\n",
        "  )\n",
        ");"
      ],
      "metadata": {
        "id": "m2fvUZ0HfRu5"
      },
      "id": "m2fvUZ0HfRu5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Lab_5_GenAI_for_BigQuery.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}